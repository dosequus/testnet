{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8,963,251 params\n",
      "Loading checkpoint from checkpoints/best-pretrained-model.pt\n",
      "Checkpoint loaded successfully.\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Config(model=Config(learning_rate=0.05, policy_output_size=4672, value_output_size=3), mcts=Config(max_nodes=3600, thinking_time=10), train=Config(num_epochs=200, num_self_play_games=100, batch_size=32, num_simulations=100, replay_buffer_size=30000, evaluation_interval=5, save_model=True, model_checkpoint_dir='checkpoints/', training_steps=250), evaluation=Config(num_simulations=800, max_depth=10, num_games=5), pretrain=Config(batch_size=8, num_epochs=10, validation_batch_size=100, validation_interval=1, alpha=0.9), visualize=True, verbose=False)\n",
      "Puzzle dataset already exists. Skipping download and extraction.\n",
      "Loading puzzles to memory...\n",
      "Already pre-processed.\n",
      "Starting pre-training...\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=3.444, elo=1271, ACC=0.375:   0%|          | 136/100000 [00:21<4:02:27,  6.86it/s]"
     ]
    }
   ],
   "source": [
    "# @title run pretraining\n",
    "import torch\n",
    "import torch.backends\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "import os\n",
    "\n",
    "from network import TakoNet, TakoNetConfig\n",
    "from pretrain import train, download_training_set\n",
    "from settings import Configuration\n",
    "\n",
    "config = Configuration().get_config()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu') \n",
    "\n",
    "model = TakoNetConfig().create_model() # pass device to create_model for GPU\n",
    "print(f\"{model.count_params():,} params\")\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "checkpoint_path = \"checkpoints/best-pretrained-model.pt\" # TODO: configure with command line args\n",
    "epoch = 0\n",
    "if os.path.isfile(checkpoint_path):\n",
    "    print(f\"Loading checkpoint from {checkpoint_path}\")\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=model.device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    print(\"Checkpoint loaded successfully.\")\n",
    "else:\n",
    "    print(f\"No checkpoint found at {checkpoint_path}, starting from scratch.\")\n",
    "\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer, \n",
    "    T_max=config.pretrain.num_epochs, \n",
    "    eta_min=1e-6, \n",
    "    verbose=True\n",
    ")\n",
    "print(config)\n",
    "download_training_set()\n",
    "train(model, optimizer, scheduler, starting_epoch=0)\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'epoch': 0\n",
    "}, f'checkpoints/best-model.pt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
